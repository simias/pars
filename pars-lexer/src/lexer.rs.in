/// Lexer implementation
pub struct Lexer<'a> {
    input_stream: &'a mut ::std::io::Read,
    buffer: Vec<u8>,
    buffer_offset: usize,
}

impl<'a> Lexer<'a> {
    pub fn new<'n>(input_stream: &'n mut ::std::io::Read) -> Lexer<'n> {
        Lexer {
            input_stream: input_stream,
            buffer: Vec::new(),
            buffer_offset: 0,
        }
    }

    pub fn next_token(&mut self %NEXT_PARAMS%) -> Result<%TOKEN_TYPE%, LexerError> {
        let mut cur_state = Some(States::State0);

        let match_start = self.buffer_offset;

        let mut accepting_state: Option<(usize, %TOKEN_TYPE%)> = None;

        while let Some(state) = cur_state {
            // XXX implement utf-8 reads. Maybe add support for custom
            // readers through a trait or something?
            let input = match self.next_utf8_char() {
                Ok(c) => c,
                Err(LexerError::EndOfFile) => {
                    if self.buffer_offset == match_start {
                        // Nothing left to match
                        return Err(LexerError::EndOfFile);
                    }
                    // Let's match what we just parsed
                    break;
                }
                Err(e) => return Err(e),
            };

            println!("Matching {}...", input);

            let next_state =
                match state {%MATCH_INPUT%
                };

            cur_state = next_state;
        }

        match accepting_state {
            Some((match_end, token)) => {
                // Backtrack to the end of the match
                self.buffer_offset = match_end;

                println!("{} matched {}", String::from_utf8_lossy(&self.buffer[match_start..match_end]), token);

                Ok(token)
            }
            None => Err(LexerError::NoMatch(match_start)),
        }
    }

    fn next_utf8_char(&mut self) -> Result<char, LexerError> {
        let mut c = [0u8; 4];

        c[0] = try!(self.next_byte());

        // Lookup table giving the number of bytes for the codepoint
        // based on bits [7:3] of the first byte. Some values are
        // invalid but we'll let `str::from_utf8` report the error
        // (here we pretend that they only need a single byte).
        let utf8_bytes: [u8; 32] = [
            // 0b0xxxxxxx
            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
            // 0b10xxxxxx (invalid for a 1st byte)
            1, 1, 1, 1, 1, 1, 1, 1,
            // 0b110xxxxx
            2, 2, 2, 2,
            // 0b1110xxxx
            3, 3,
            // 0b11110xxx
            4,
            // 0b11111xxx (invalid)
            1,
        ];

        let mut num_bytes = utf8_bytes[(c[0] >> 3) as usize];

        for i in 1..num_bytes {
            let b =
                match self.next_byte() {
                    Ok(b) => b,
                    Err(LexerError::EndOfFile) => {
                        // Truncated UTF-8 sequence.
                        num_bytes = i;
                        break;
                    }
                    Err(e) => return Err(e),
                };

            c[i as usize] = b;
        }

        let num_bytes = num_bytes as usize;

        let s = try!(::std::str::from_utf8(&c[0..num_bytes]));

        Ok(s.chars().next().unwrap())
    }

    fn next_byte(&mut self) -> Result<u8,  LexerError> {
        if self.buffer.len() == self.buffer_offset {
            // Reached the end of the buffer, refill
            let buf_size = 4096;

            self.buffer.resize(buf_size + self.buffer_offset, 0);

            let count =
                try!(::std::io::Read::read(self.input_stream,
                                           &mut self.buffer[self.buffer_offset..]));


            self.buffer.truncate(self.buffer_offset + count);

            if count == 0 {
                return Err(LexerError::EndOfFile);
            }
        }

        let b = self.buffer[self.buffer_offset];
        self.buffer_offset += 1;

        Ok(b)
    }
}

/// All the states used by this lexer.
enum States {%DECLARE_STATES%
}

/// Lexer error type
#[derive(Debug)]
pub enum LexerError {
    EndOfFile,
    NoMatch(usize),
    Utf8Error(::std::str::Utf8Error),
    IoError(::std::io::Error),
}

impl ::std::convert::From<::std::io::Error> for LexerError {
    fn from(e: ::std::io::Error) -> LexerError {
        LexerError::IoError(e)
    }
}

impl ::std::convert::From<::std::str::Utf8Error> for LexerError {
    fn from(e: ::std::str::Utf8Error) -> LexerError {
        LexerError::Utf8Error(e)
    }
}
