/// Lexer implementation
pub struct Lexer<'a> {
    input_stream: &'a mut ::std::io::Read,
    buffer: Vec<u8>,
    buffer_offset: usize,
}

impl<'a> Lexer<'a> {
    pub fn new<'n>(input_stream: &'n mut ::std::io::Read) -> Lexer<'n> {
        Lexer {
            input_stream: input_stream,
            buffer: Vec::new(),
            buffer_offset: 0,
        }
    }

    /// Parse the input stream until a token is found. If we reach the
    /// end of the stream `Ok(None)` is returned.
    pub fn next_token(&mut self)
                      -> Result<Option<%TOKEN_TYPE%>, LexerError> {
        loop {
            match self.next_match() {
                // We had a match but no token was generated, continue
                // the lexing
                Ok(None) => continue,
                // Found a token
                Ok(Some(t)) => return Ok(Some(t)),
                // End of file, return `None`
                Err(LexerError::EndOfFile) => return Ok(None),
                Err(e) => return Err(e),
            }
        }
    }

    fn next_match(&mut self)
                  -> Result<Option<%TOKEN_TYPE%>, LexerError> {
        let mut cur_state = Some(State::State0);

        let match_start = self.buffer_offset;

        let mut accepting_state: Option<(usize, AcceptingState)> = None;

        while let Some(state) = cur_state {
            // XXX implement utf-8 reads. Maybe add support for custom
            // readers through a trait or something?
            let input = match self.next_utf8_char() {
                Ok(c) => c,
                Err(LexerError::EndOfFile) => {
                    if self.buffer_offset == match_start {
                        // Nothing left to match
                        return Err(LexerError::EndOfFile);
                    }
                    // Let's match what we just parsed
                    break;
                }
                Err(e) => return Err(e),
            };

            let next_state =
                match state {%MATCH_INPUT%
                };

            cur_state = next_state;
        }

        match accepting_state {
            Some((match_end, state)) => {
                // Backtrack to the end of the match
                self.buffer_offset = match_end;

                let _lexer_match = Match::new(match_start,
                                              match_end,
                                              &self.buffer);

                let maybe_token =
                    match state {%MATCH_ACCEPTING_STATE%
                    };

                Ok(maybe_token)
            }
            None => Err(LexerError::NoMatch(match_start)),
        }
    }

    fn next_utf8_char(&mut self) -> Result<char, LexerError> {
        let mut c = [0u8; 4];

        c[0] = try!(self.next_byte());

        // Lookup table giving the number of bytes for the codepoint
        // based on bits [7:3] of the first byte. Some values are
        // invalid but we'll let `str::from_utf8` report the error
        // (here we pretend that they only need a single byte).
        let utf8_bytes: [u8; 32] = [
            // 0b0xxxxxxx
            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
            // 0b10xxxxxx (invalid for a 1st byte)
            1, 1, 1, 1, 1, 1, 1, 1,
            // 0b110xxxxx
            2, 2, 2, 2,
            // 0b1110xxxx
            3, 3,
            // 0b11110xxx
            4,
            // 0b11111xxx (invalid)
            1,
        ];

        let mut num_bytes = utf8_bytes[(c[0] >> 3) as usize];

        for i in 1..num_bytes {
            let b =
                match self.next_byte() {
                    Ok(b) => b,
                    Err(LexerError::EndOfFile) => {
                        // Truncated UTF-8 sequence.
                        num_bytes = i;
                        break;
                    }
                    Err(e) => return Err(e),
                };

            c[i as usize] = b;
        }

        let num_bytes = num_bytes as usize;

        let s = try!(::std::str::from_utf8(&c[0..num_bytes]));

        Ok(s.chars().next().unwrap())
    }

    fn next_byte(&mut self) -> Result<u8,  LexerError> {
        use ::std::io::Read;

        if self.buffer.len() == self.buffer_offset {
            // Reached the end of the buffer, refill
            let buf_size = 4096;

            self.buffer.resize(buf_size + self.buffer_offset, 0);

            let count =
                try!(Read::read(self.input_stream,
                                &mut self.buffer[self.buffer_offset..]));


            self.buffer.truncate(self.buffer_offset + count);

            if count == 0 {
                return Err(LexerError::EndOfFile);
            }
        }

        let b = self.buffer[self.buffer_offset];
        self.buffer_offset += 1;

        Ok(b)
    }
}

/// Match object containing informations about the currently matched
/// sequence.
#[allow(dead_code)]
struct Match<'a> {
    start: usize,
    end: usize,
    buffer: &'a [u8],
}

impl<'a> Match<'a> {
    pub fn new<'n>(start: usize, end: usize, buffer: &'n [u8]) -> Match<'n> {
        Match {
            start: start,
            end: end,
            buffer: buffer,
        }
    }

    #[allow(dead_code)]
    pub fn as_bytes(&self) -> ::std::borrow::Cow<'a, [u8]> {
        ::std::borrow::Cow::Borrowed(&self.buffer[self.start..self.end])
    }

    #[allow(dead_code)]
    pub fn as_str(&self) -> ::std::borrow::Cow<'a, str> {
        // For now we always return a reference but when we change the
        // buffering code we might have to build a string from scratch
        // if the match isn't contiguous in memory

        let b = &self.buffer[self.start..self.end];

        // This shouldn't ever fail since we validate the string while
        // parsing. We could probably use the `_unchecked` variant
        // instead.
        let s = ::std::str::from_utf8(b).unwrap();

        ::std::borrow::Cow::Borrowed(s)
    }
}

/// All the states used by this lexer.
#[derive(Debug, Copy, Clone, PartialEq, Eq)]
enum State {%DECLARE_STATES%
}

/// The subset of accepting states used by this lexer.
#[derive(Debug, Copy, Clone, PartialEq, Eq)]
enum AcceptingState {%DECLARE_ACCEPTING_STATES%
}

/// Lexer error type
#[derive(Debug)]
pub enum LexerError {
    EndOfFile,
    NoMatch(usize),
    Utf8Error(::std::str::Utf8Error),
    IoError(::std::io::Error),
}

impl ::std::convert::From<::std::io::Error> for LexerError {
    fn from(e: ::std::io::Error) -> LexerError {
        LexerError::IoError(e)
    }
}

impl ::std::convert::From<::std::str::Utf8Error> for LexerError {
    fn from(e: ::std::str::Utf8Error) -> LexerError {
        LexerError::Utf8Error(e)
    }
}
